{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":12566762,"sourceType":"datasetVersion","datasetId":7935915},{"sourceId":12567624,"sourceType":"datasetVersion","datasetId":7936526},{"sourceId":12568124,"sourceType":"datasetVersion","datasetId":7936899}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom glob import glob\nimport pandas as pd\n\n# âœ… Step 1: Load the CSV file (metadata)\ncsv_path = \"/kaggle/input/data/Data_Entry_2017.csv\"\ndf = pd.read_csv(csv_path)\n\n# âœ… Step 2: Filter only PA (PosteroAnterior) view images\ndf_pa = df[df['View Position'] == 'PA'].copy()\n\nprint(\"Number of PA images:\", len(df_pa))\nprint(df_pa[['Image Index', 'Finding Labels', 'View Position']].head())\n\n# âœ… Step 3: Search for all image paths in the dataset folders\n# Each folder is like: images_001, images_002, ..., images_012\nimage_folders = [f\"/kaggle/input/data/images_{str(i).zfill(3)}/images\" for i in range(1, 13)]\n\nall_image_paths = []\nfor folder in image_folders:\n    all_image_paths.extend(glob(os.path.join(folder, \"*.png\")))\n\n# âœ… Step 4: Create a dictionary mapping image name âžœ full image path\nimage_paths_dict = {os.path.basename(p): p for p in all_image_paths}\n\n# âœ… Step 5: Add a new column to df_pa with the full image path\ndf_pa['image_path'] = df_pa['Image Index'].map(image_paths_dict)\n\n# âœ… Step 6: Check for missing paths (should be 0 if everything is correct)\nprint(\"Missing paths:\", df_pa['image_path'].isnull().sum())\nprint(df_pa[['Image Index', 'image_path']].head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-24T16:46:47.810638Z","iopub.execute_input":"2025-07-24T16:46:47.811010Z","iopub.status.idle":"2025-07-24T16:46:49.231514Z","shell.execute_reply.started":"2025-07-24T16:46:47.810987Z","shell.execute_reply":"2025-07-24T16:46:49.230072Z"}},"outputs":[{"name":"stdout","text":"Number of PA images: 67310\n        Image Index          Finding Labels View Position\n0  00000001_000.png            Cardiomegaly            PA\n1  00000001_001.png  Cardiomegaly|Emphysema            PA\n2  00000001_002.png   Cardiomegaly|Effusion            PA\n3  00000002_000.png              No Finding            PA\n4  00000003_000.png                  Hernia            PA\nMissing paths: 0\n        Image Index                                         image_path\n0  00000001_000.png  /kaggle/input/data/images_001/images/00000001_...\n1  00000001_001.png  /kaggle/input/data/images_001/images/00000001_...\n2  00000001_002.png  /kaggle/input/data/images_001/images/00000001_...\n3  00000002_000.png  /kaggle/input/data/images_001/images/00000002_...\n4  00000003_000.png  /kaggle/input/data/images_001/images/00000003_...\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom glob import glob\n\n# ðŸŸ¢ 1. Load the CSV\ncsv_path = \"/kaggle/input/single-disease-only/single_disease_only.csv\"\ndf = pd.read_csv(csv_path)\n\n# ðŸŸ¢ 2. Extract disease label columns\nall_labels = list(df.columns[1:])  # exclude 'Image Index'\nprint(\"Diseases:\", all_labels)\n\n# ðŸŸ¢ 3. Split data\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n\n# ðŸŸ¢ 4. Map image names to their full paths\nimages_dir = \"/kaggle/input/data\"\nimage_folders = [f\"{images_dir}/images_{str(i).zfill(3)}/images\" for i in range(1, 13)]\n\nimage_paths_dict = {}\nfor folder in image_folders:\n    for path in glob(os.path.join(folder, \"*.png\")):\n        image_paths_dict[os.path.basename(path)] = path\n\ntrain_df[\"image_path\"] = train_df[\"Image Index\"].map(image_paths_dict)\nval_df[\"image_path\"] = val_df[\"Image Index\"].map(image_paths_dict)\n\n# ðŸŸ¢ 5. Define PyTorch Dataset\nclass ChestXrayDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe.reset_index(drop=True)\n        self.transform = transform\n        self.labels = dataframe[all_labels].values.astype(\"float32\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = self.df.loc[idx, \"image_path\"]\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        label = torch.tensor(self.labels[idx])\n        return image, label\n\n# ðŸŸ¢ 6. Transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\n# ðŸŸ¢ 7. Datasets & Loaders\ntrain_dataset = ChestXrayDataset(train_df, transform=train_transform)\nval_dataset = ChestXrayDataset(val_df, transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n\nprint(\"âœ… Data ready. Number of training samples:\", len(train_dataset))\nprint(\"âœ… Number of validation samples:\", len(val_dataset))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-24T18:32:04.811236Z","iopub.execute_input":"2025-07-24T18:32:04.811913Z","iopub.status.idle":"2025-07-24T18:32:06.491564Z","shell.execute_reply.started":"2025-07-24T18:32:04.811873Z","shell.execute_reply":"2025-07-24T18:32:06.490557Z"}},"outputs":[{"name":"stdout","text":"Diseases: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'No Finding', 'Nodule', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\nâœ… Data ready. Number of training samples: 45704\nâœ… Number of validation samples: 11426\n","output_type":"stream"}],"execution_count":2}]}